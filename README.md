# ğŸ”„ AMQP Transactions Microservices

## ğŸ¯ Objetivo
Sistema robusto de microserviÃ§os para processamento de transaÃ§Ãµes financeiras em larga escala usando **RabbitMQ** e **PostgreSQL**. Implementa padrÃµes de resiliÃªncia, idempotÃªncia e observabilidade.

## ğŸ› ï¸ Tecnologias
- **Linguagem:** Go 1.22
- **Message Broker:** RabbitMQ 3 (AMQP) com Dead Letter Queue
- **Banco de Dados:** PostgreSQL 15 com GORM
- **Arquitetura:** MicroserviÃ§os com Worker Pool
- **ContainerizaÃ§Ã£o:** Docker Compose
- **Observabilidade:** Health checks, mÃ©tricas Prometheus-style

## ğŸš€ Arquitetura

```
CSV Files (./data)
      â†“
Producer MS (4 workers)
      â†“ (streaming, persistent messages)
RabbitMQ (durable queue + DLQ)
      â†“ (QoS=100, autoAck=false)
Consumer MS (5 workers, batch insert)
      â†“ (idempotent ON CONFLICT)
PostgreSQL (transactions table)
```

### CaracterÃ­sticas de ProduÃ§Ã£o

**Producer:**
- âœ… Streaming de CSV (nÃ£o carrega tudo em memÃ³ria)
- âœ… Worker pool com canais dedicados
- âœ… Mensagens persistentes (DeliveryMode=2)
- âœ… Publisher confirms para garantir entrega
- âœ… Retry automÃ¡tico com backoff
- âœ… Health e mÃ©tricas HTTP

**Consumer:**
- âœ… QoS para limitar mensagens in-flight
- âœ… AutoAck=false com ack manual apÃ³s persistÃªncia
- âœ… Batch inserts para performance
- âœ… IdempotÃªncia via UNIQUE constraint + ON CONFLICT
- âœ… Dead Letter Queue para mensagens malformadas
- âœ… Requeue em erros transitÃ³rios
- âœ… Worker pool concorrente
- âœ… Health e mÃ©tricas HTTP

## ğŸ“ Estrutura do Projeto

```
amqp-transactions-ms/
â”œâ”€â”€ data/                          # CSV files (montado em /app/data)
â”œâ”€â”€ transaction-producer-ms/
â”‚   â”œâ”€â”€ main.go                    # Producer com streaming e worker pool
â”‚   â”œâ”€â”€ Dockerfile                 # Multi-stage build
â”‚   â””â”€â”€ go.mod
â”œâ”€â”€ transaction-consumer-ms/
â”‚   â”œâ”€â”€ main.go                    # Consumer com batch e idempotÃªncia
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ go.mod
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ e2e_test.sh               # Script de teste end-to-end
â”œâ”€â”€ docker-compose.yml             # OrquestraÃ§Ã£o completa
â””â”€â”€ README.md
```

## ğŸš¦ Quick Start

### PrÃ©-requisitos
- Docker & Docker Compose
- Arquivos CSV em `./data/`

### Executar

```bash
# Subir todos os serviÃ§os
docker-compose up --build

# Ou em background
docker-compose up -d --build

# Ver logs
docker-compose logs -f producer
docker-compose logs -f consumer

# Parar e limpar
docker-compose down -v
```

### Executar Testes End-to-End

```bash
./scripts/e2e_test.sh
```

O script irÃ¡:
1. Limpar ambiente anterior
2. Subir serviÃ§os
3. Verificar health checks
4. Validar processamento
5. Testar idempotÃªncia
6. Exibir mÃ©tricas

## ğŸ“Š Monitoramento

### Health Endpoints

```bash
# Producer (porta 8080)
curl http://localhost:8080/healthz

# Consumer (porta 8081)
curl http://localhost:8081/healthz
```

### MÃ©tricas (Prometheus-style)

```bash
# Producer
curl http://localhost:8080/metrics

# Consumer
curl http://localhost:8081/metrics
```

MÃ©tricas disponÃ­veis:
- `producer_messages_published_total` - Total de mensagens publicadas
- `producer_messages_failed_total` - Total de falhas
- `consumer_messages_processed_total` - Total processadas
- `consumer_messages_duplicate_total` - Total de duplicatas (idempotÃªncia)
- `consumer_messages_error_total` - Total de erros

### RabbitMQ Management UI

```bash
# Acessar em http://localhost:15672
# UsuÃ¡rio: guest
# Senha: guest
```

### Consultar Banco de Dados

```bash
# Conectar ao Postgres
docker exec -it postgres psql -U user -d transactions

# Consultas Ãºteis
SELECT COUNT(*) FROM transactions;
SELECT * FROM transactions LIMIT 10;
SELECT COUNT(*) FROM transactions WHERE created_at > NOW() - INTERVAL '5 minutes';
```

## âš™ï¸ ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente

**Producer:**
```bash
RABBITMQ_URL=amqp://guest:guest@rabbitmq:5672/
INPUT_PATH=/app/data
QUEUE_NAME=transactions_queue
WORKERS=4
HTTP_PORT=8080
```

**Consumer:**
```bash
RABBITMQ_URL=amqp://guest:guest@rabbitmq:5672/
POSTGRES_DSN=host=postgres user=user password=password dbname=transactions port=5432 sslmode=disable
QUEUE_NAME=transactions_queue
PREFETCH=100
WORKERS=5
BATCH_SIZE=100
HTTP_PORT=8081
```

## ğŸ§ª Testes

### Casos de Teste Cobertos

**CT1: Happy Path**
- âœ… CSV processado completamente
- âœ… Mensagens publicadas na fila
- âœ… Todas persistidas no banco
- âœ… Fila esvaziada

**CT2: IdempotÃªncia**
- âœ… Reprocessar mesmo CSV nÃ£o cria duplicatas
- âœ… Contador de duplicatas nas mÃ©tricas

**CT3: ResiliÃªncia**
- âœ… Mensagens requeued em erros transitÃ³rios
- âœ… Mensagens para DLQ em erros permanentes

**CT4: Performance**
- âœ… Processamento de 10k+ linhas em < 5 minutos
- âœ… Sem memory leak com streaming

## ğŸ”§ Troubleshooting

### Producer nÃ£o processa CSV

```bash
# Verificar se CSV estÃ¡ no volume
docker exec producer ls -la /app/data

# Verificar logs
docker-compose logs producer
```

### Consumer nÃ£o consome mensagens

```bash
# Verificar conexÃ£o com RabbitMQ
docker-compose logs consumer | grep "Conectado ao RabbitMQ"

# Verificar fila no RabbitMQ UI
# http://localhost:15672/#/queues
```

### Dados nÃ£o aparecem no banco

```bash
# Verificar se consumer estÃ¡ rodando
docker ps | grep consumer

# Ver logs de erro
docker-compose logs consumer | grep -i error

# Verificar conexÃ£o do banco
docker exec postgres pg_isready -U user -d transactions
```

## ğŸ“ˆ Performance

### Benchmarks (10k transaÃ§Ãµes)

- **Throughput:** ~500-1000 msg/s
- **LatÃªncia:** < 100ms (end-to-end)
- **MemÃ³ria Producer:** ~50MB
- **MemÃ³ria Consumer:** ~100MB
- **Tempo total:** 20-60 segundos (depende do hardware)

### OtimizaÃ§Ãµes Aplicadas

1. **Streaming de CSV** - evita carregar arquivo completo na memÃ³ria
2. **Worker pools** - paralelismo em producer e consumer
3. **Batch inserts** - reduz round-trips ao banco
4. **Publisher confirms** - garante entrega sem perda
5. **Prefetch limit** - evita sobrecarga de memÃ³ria no consumer
6. **Connection pooling** - GORM gerencia pool do Postgres

## ğŸ“ Principais Aprendizados

### ResiliÃªncia
- Mensagens durÃ¡veis sobrevivem a restart do RabbitMQ
- DLQ captura mensagens problemÃ¡ticas
- Requeue automÃ¡tico em falhas transitÃ³rias
- Health checks permitem restart automÃ¡tico

### IdempotÃªncia
- UNIQUE constraint no ID da transaÃ§Ã£o
- ON CONFLICT DO NOTHING no GORM
- Contadores de duplicatas nas mÃ©tricas
- Ack apÃ³s persistÃªncia bem-sucedida

### Observabilidade
- Logs estruturados com contexto
- MÃ©tricas Prometheus-style
- Health endpoints para orquestraÃ§Ã£o
- EstatÃ­sticas em tempo real

### Escalabilidade
- Worker pools ajustÃ¡veis via env vars
- Processamento paralelo em mÃºltiplos nÃ­veis
- Batch processing para throughput
- Stateless design permite scaling horizontal

## ğŸ“ CritÃ©rios de AceitaÃ§Ã£o

- [x] AC1: docker-compose up completa e expÃµe RabbitMQ UI
- [x] AC2: Producer processa CSV grande (10k+) sem OOM
- [x] AC3: Consumer persiste todas as transaÃ§Ãµes em < 5 min
- [x] AC4: Reprocessamento nÃ£o cria duplicatas
- [x] AC5: DLQ captura mensagens malformadas
- [x] AC6: Health endpoints retornam 200 OK

## ğŸ¤ Contribuindo

```bash
# Clone o repositÃ³rio
git clone <repo-url>

# Entre no diretÃ³rio
cd amqp-transactions-ms

# Coloque CSVs em ./data/

# Execute os testes
./scripts/e2e_test.sh
```

## ğŸ“„ LicenÃ§a

Este projeto Ã© para fins educacionais e de aprendizado.

## ğŸ‘¨â€ï¿½ Autor

Desenvolvido como projeto de estudo de arquitetura de microserviÃ§os com RabbitMQ e PostgreSQL.
- **CSV parsing:** Leitura e validaÃ§Ã£o de dados
- **Type conversion:** ConversÃ£o para tipos apropriados
- **JSON serialization:** Formato padrÃ£o para comunicaÃ§Ã£o
- **Data validation:** Tratamento de dados invÃ¡lidos

## ğŸ§  Conceitos TÃ©cnicos Estudados

### 1. **SOLID Principles**
```go
// Single Responsibility - Cada serviÃ§o tem uma responsabilidade
type CSVService struct {
    queue Queue
}

// Dependency Inversion - AbstraÃ§Ã£o do message broker
type Queue interface {
    Publish(data []byte) error
}
```

### 2. **Clean Architecture**
```go
// Camadas bem definidas
internal/
â”œâ”€â”€ dto/        # Entities
â”œâ”€â”€ service/    # Use Cases
â””â”€â”€ queue/      # Infrastructure
```

### 3. **Producer-Consumer Pattern**
```go
// Producer: Processa CSV e envia para queue
func (s *CSVService) ProcessFile(filepath string) error {
    // LÃª CSV, converte e publica
}

// Consumer: Recebe da queue e processa
func (c *Consumer) ProcessMessage(msg []byte) error {
    // Deserializa e processa transaÃ§Ã£o
}
```

## ğŸš§ Desafios Enfrentados
1. **SincronizaÃ§Ã£o:** CoordenaÃ§Ã£o entre producer e consumer
2. **Error handling:** Tratamento de falhas em sistemas distribuÃ­dos
3. **Data consistency:** Garantir integridade dos dados
4. **Performance:** OtimizaÃ§Ã£o do throughput de mensagens
5. **Monitoring:** Observabilidade em arquitetura distribuÃ­da

## ğŸ“š Recursos Utilizados
- [RabbitMQ Documentation](https://www.rabbitmq.com/documentation.html)
- [Go AMQP Library](https://github.com/streadway/amqp)
- [Microservices Patterns](https://microservices.io/patterns/)
- [Clean Architecture in Go](https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html)

## ğŸ“ˆ PrÃ³ximos Passos
- [ ] Implementar Dead Letter Queue
- [ ] Adicionar mÃ©tricas e monitoring
- [ ] Implementar circuit breaker
- [ ] Adicionar testes de integraÃ§Ã£o
- [ ] Implementar retry policies
- [ ] Adicionar tracing distribuÃ­do

## ğŸ”— Projetos Relacionados
- [Go Antifraud MS](../go-antifraud-ms/) - MicroserviÃ§o de detecÃ§Ã£o de fraude
- [Go PriceGuard API](../go-priceguard-api/) - API com Clean Architecture
- [Transaction Consumer MS](../transaction-consumer-ms/) - Consumer especÃ­fico

---

**Desenvolvido por:** Felipe Macedo  
**Contato:** contato.dev.macedo@gmail.com  
**GitHub:** [FelipeMacedo](https://github.com/felipemacedo1)  
**LinkedIn:** [felipemacedo1](https://linkedin.com/in/felipemacedo1)

> ğŸ’¡ **ReflexÃ£o:** Este projeto foi fundamental para compreender arquiteturas distribuÃ­das e comunicaÃ§Ã£o assÃ­ncrona. A implementaÃ§Ã£o de microserviÃ§os com RabbitMQ proporcionou experiÃªncia prÃ¡tica em sistemas escalÃ¡veis e resilientes.